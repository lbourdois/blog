---
permalink: /other/
title: "Autre"
classes: wide
---

Sur cette page vous pouvez trouver les contenus sur lesquels j'ai travaill√© (√† titre personnel ou professionnel) mais qui sont r√©f√©renc√©s sur d'autres sites que mon blog personnel. Il s'agit principalement de traductions de cours, et des cr√©ations de jeux de donn√©es et de mod√®les.

# Traductions
## Cours de Yann Le Cun et Alfredo Canziani de la NYU
Cette traduction a √©t√© la plus longue √† effectuer s'√©talant de 2020 √† 2022.  
Le contenu est structur√© en 19 unit√©s r√©parties sur 33 vid√©os üé• de cours (cours magistraux et travaux dirig√©s) d‚Äôune dur√©e totale d‚Äôenviron 45H, 74 pages web üåê r√©sumant les vid√©os via les notes prises par les √©tudiants pendant le cours, et 16 notebooks Jupyter üìì (en PyTorch) utilis√©s lors des TD. Enfin un jeu de donn√©es de plus de 3000 donn√©es parall√®les v√©rifi√©es manuellement a √©t√© cr√©√© pour entra√Æner un mod√®le de traduction.  
Vous pouvez retrouver toutes ces ressources sur le site internet d√©di√© qui a √©t√© con√ßu √† l'occasion : [https://lbourdois.github.io/cours-dl-nyu/](https://lbourdois.github.io/cours-dl-nyu/).


## Cours de Hugging Face ü§ó
### Cours de NLP
En 2022, j'ai traduit le cours de traitement automatique du langage de Hugging Face.  
Le contenu est structur√© en 10 chapitres comprenant un total de 76 vid√©os üé• d'une dur√©e totale d'environ 5H, de 78 pages web üåê et 61 notebooks Jupyter üìì  (en PyTorch et Tensorflow).  
Vous pouvez retrouver toutes ces ressources sur le site de [Hugging Face](https://huggingface.co/learn/nlp-course/fr/chapter1/1).

### Cours d'audio
En 2023, j'ai traduit le cours de traitement automatique du langage de Hugging Face.  
Le contenu est structur√© en 8 unit√©s r√©parties sur 46 pages web üåê.  
Vous pouvez retrouver toutes ces ressources sur le site de [Hugging Face](https://huggingface.co/learn/audio-course/fr/).

### Cours sur les mod√®les de diffusion
En 2023, j'ai traduit le cours sur les mod√®les de diffusion de Hugging Face.  
Le contenu est structur√© en 4 chapitres portant sur 17 pages web üåê et 8 notebooks Jupyter üìì (en PyTorch).  
Vous pouvez retrouver toutes ces ressources sur le GitHub de [Hugging Face](https://github.com/huggingface/diffusion-models-class/tree/main/units/fr) (le contenu n'ayant pas encore √©t√© propag√© sur le site officiel).

<br><br>

# Mod√®les et jeux de donn√©es

## FAT5
Le FAT5 est une impl√©mentation du [T5](https://arxiv.org/abs/1910.10683) en PyTorch avec un objectif [UL2](https://arxiv.org/abs/2205.05131) optimis√© pour GPGPU d√©velopp√© avec [Boris ALBAR](https://b-albar.github.io/portfolio/).  
Elle utilise des noyaux CUDA et Triton personnalis√©s ainsi que des optimisations sp√©cifiques pour augmenter le d√©bit et r√©duire l'utilisation de la m√©moire pour l'entra√Ænement et l'inf√©rence d'un facteur 2 par rapport √† l'impl√©mentation originale disponible dans Hugging Face.  
Nous l'avons appliqu√©e en pr√©-entra√Ænant un mod√®le en fran√ßais de 147M param√®tres en utilisant uniquement une A100. Nous estimons ainsi pouvoir ramener le prix de pr√©-entra√Ænement d'un tel mod√®le √† seulement 2200‚Ç¨ (estimation faite sur une instance OVH).   
Le code de pr√©-entrainement est disponible sur [GitHub](https://github.com/catie-aq/flashT5) sous licence Apache-2.0 et les poids du mod√®le entra√Æn√© sur le compte [Hugging Face du CATIE](https://huggingface.co/CATIE-AQ). Un article de blog d√©taillant notre m√©thodologie est disponible [ici](https://huggingface.co/spaces/CATIE-AQ/FAT5-rapport).

## NER
Le NERmemBERT est un mod√®le de Reconnaissance d‚ÄôEntit√©s Nomm√©es en fran√ßais capable d‚Äô√©tiqueter jusqu‚Äô√† 4 entit√©s (Personnalit√©s, Lieux, Organisations, Divers tel que des noms d‚Äô≈ìuvre, de maladies, etc.). Il est disponible en taille base (110M de param√®tres) et large (336M). Les poids sont disponibles gratuitement en open-source, tout comme les jeux de donn√©es ayant servis √† l‚Äôentra√Ænement. Le tout est disponible sur le compte [Hugging Face du CATIE](https://huggingface.co/collections/CATIE-AQ/catie-french-ner-pack-658aefafe3f7a2dcf0e4dbb4). Un article de blog d√©taillant la m√©thodologie adopt√©e est disponible [ici](https://lbourdois.github.io/blog/NER/).

## Question Answering
Le QAmemBERT est un mod√®le de r√©ponse aux questions en fran√ßais capable d‚Äôindiquer si la r√©ponse √† une question est pr√©sente ou pas dans un texte de contexte associ√©. Il est disponible en taille base (110M de param√®tres) et large (335M). Les poids sont disponibles gratuitement en open-source, tout comme le jeu de donn√©es ayant servis √† l‚Äôentra√Ænement. Le tout est disponible sur le compte [Hugging Face du CATIE](https://huggingface.co/collections/CATIE-AQ/catie-french-qa-pack-650821750f44c341cdb8ec91). Un article de blog d√©taillant la m√©thodologie adopt√©e est disponible [ici](https://lbourdois.github.io/blog/QA/).

## DFP
*Dataset of French Prompts* (DFP) contient 113 129 978 lignes portant sur 30 t√¢ches de NLP diff√©rentes.  
724 prompts ont √©t√© √©crits sous forme imp√©rative, de tutoiement et de vouvoiement afin de couvrir autant que possible les donn√©es de pr√©-entra√Ænement utilis√©es par le mod√®le qui utilisera ces donn√©es et qui nous sont inconnues.  
Les colonnes *inputs* et *targets* suivent le m√™me format que l'ensemble de donn√©es [xP3](https://huggingface.co/datasets/bigscience/xP3) de Muennighoff et al.  
L'ensemble des d√©tails est disponible sur [Hugging Face](https://huggingface.co/datasets/CATIE-AQ/DFP).
