---
title: "LA RECONNAISSANCE D’ENTITÉS NOMMÉES (NER)"
tags:
  - NLP
  - NER
excerpt : "NLP - Explication de la tâche de reconnaissance d’entités nommées"
header :
    overlay_color: "#1C2A4D"
    teaser : "https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/NER/CONLL.png"
author_profile: false
sidebar:
    nav: sidebar-sample
classes: wide
---

# <span style="color: #FF0000"> **Avant-propos** </span>
Cet article est une republication de celui que j'ai rédigé sur le [blog Vaniila](https://blog.vaniila.ai/NER/) pour le [CATIE](https://www.catie.fr/).  
La version initiale de cet article de blog a été mise en ligne en janvier 2024.
Une actualisation a eu lieu en novembre 2024 pour référencer quatre nouveaux modèles. 

<br><br> 

# <span style="color: #FF0000"> **Qu’est-ce que la reconnaissance d’entités nommées ?** </span>

La reconnaissance d’entités nommées (souvent abrégée en NER d’après l’anglais <i>Named Entity Recognition</i>) est une tâche de NLP consistant à étiqueter les séquences de mots d’un texte qui sont des noms de choses (personnes, sociétés, lieux, maladies, etc.).<br>
D’un point de vue technique, la tâche de NER peut être considérée comme de la classification où au lieu de classifier au niveau de la phrase entière (pour de l’analyse de sentiment par exemple), l’on classifie au niveau du mot en indiquant à quelle classe appartient le mot traité.

<br><br> 

# <span style="color: #FF0000"> **Jeux de données de NER** </span>

Le jeu de données le plus connu et faisant référence en NER, est le jeu de données <a href="https://www.clips.uantwerpen.be/conll2003/ner/"> CoNLL-2003 (<i>Conference on Computational Natural Language Learning</i>)</a> de Erik F. Tjong Kim Sang et Fien De Meulderet (2003). Créé pour l’anglais et l’allemand, les autres langues ont généralement adopté son formatage. <br>
Ci-dessous un exemple de lignes de ce jeu de données : <br>

<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/NER/CONLL.png">
  <figcaption>
  <i>Exemple d’une ligne du jeu de données CoNLL-2003</i>
  </figcaption>
</figure>
</center>


En ce qui concerne le français, des jeux de données ont été créés suivant la méthodologie de CoNLL-2003. On peut citer : <br>
-	<a href="http://dx.doi.org/10.1016/j.artint.2012.03.006">WikiNER</a> de Nothman et al. (2013) qui est un jeu de données (pour la partie en français) de 120 682 données d’entraînement et 13 410 de test. Les entités annoncées sont LOC (Localisations), ORG (Organisations), PER (Personnalités) et MISC (Divers) et sont réparties de la façon suivante :<br>


<center>
<table>
<thead>
<tr>
<th>Split</th>
<th>O</th>
<th>PER</th>
<th>LOC</th>
<th>ORG</th>
<th>MISC</th>
</tr>
</thead>
<tbody>
<tr>
<td>train</td>
<td>2 781 968</td>
<td>116 633</td>
<td>140 345</td>
<td>41 547</td>
<td>73 411</td>
</tr>
<tr>
<td>test</td>
<td>305 131</td>
<td>13 345</td>
<td>15 220</td>
<td>3 896</td>
<td>8 183</td>
</tr>
</tbody>
</table>
</center>



-	<a href="https://arxiv.org/abs/1902.00193">Wikiann</a> de Rahimi et al. (2019) based on Pan, Xiaoman, et al. (2019) qui est un jeu de données (pour la partie en français)  avec 20 000 données d’entraînement, 10 000 de validation et 10 000 de test. Les entités annoncées sont LOC, ORG, PER et MISC et sont réparties de la façon suivante :<br>


<center>
<table>
<thead>
<tr>
<th>Split</th>
<th>O</th>
<th>PER</th>
<th>LOC</th>
<th>ORG</th>
</tr>
</thead>
<tbody>
<tr>
<td>train</td>
<td>65 292</td>
<td>21 992</td>
<td>21 273</td>
<td>28 231</td>
</tr>
<tr>
<td>validation</td>
<td>32 167</td>
<td>10 826</td>
<td>10 826</td>
<td>14 401</td>
</tr>
<tr>
<td>test</td>
<td>32 612</td>
<td>11 027</td>
<td>10 844</td>
<td>14 271</td>
</tr>
</tbody>
</table>
</center>


-	<a href="https://aclanthology.org/2022.findings-naacl.60/">MultiNERD</a> de Tedeschi et Navigli (2022) qui est un jeu de données (pour la partie en français) de 140 880 données d’entraînement, de 17 610 de validation et de 17 695 de test. Les entités annoncées sont PER, LOC, ORG, ANIM, BIO, CEL, DIS, EVE, FOOD, INST, MEDIA, PLANT, MYTH, TIME, VEHI et sont réparties de la façon suivante :<br>

 
<table>
<thead>
<tr>
<th>Split</th>
<th>O</th>
<th>PER</th>
<th>LOC</th>
<th>ORG</th>
<th>ANIM</th>
<th>BIO</th>
<th>CEL</th>
<th>DIS</th>
<th>EVE</th>
<th>FOOD</th>
<th>INST</th>
<th>MEDIA</th>
<th>MYTH</th>
<th>PLANT</th>
<th>TIME</th>
<th>VEHI</th>
</tr>
</thead>
<tbody>
<tr>
<td>train</td>
<td>2 979 567</td>
<td>151 201</td>
<td>218 858</td>
<td>109 429</td>
<td>12 800</td>
<td>21</td>
<td>3 031</td>
<td>4 107</td>
<td>20 523</td>
<td>3 282</td>
<td>992</td>
<td>19 943</td>
<td>1 591</td>
<td>4 543</td>
<td>23 555</td>
<td>1 129</td>
</tr>
<tr>
<td>validation</td>
<td>402 643</td>
<td>17 599</td>
<td>14 151</td>
<td>3 498</td>
<td>766</td>
<td>0</td>
<td>392</td>
<td>698</td>
<td>2 009</td>
<td>795</td>
<td>157</td>
<td>1 444</td>
<td>541</td>
<td>832</td>
<td>6 456</td>
<td>156</td>
</tr>
<tr>
<td>test</td>
<td>406 146</td>
<td>18 591</td>
<td>14 124</td>
<td>3 685</td>
<td>844</td>
<td>6</td>
<td>390</td>
<td>709</td>
<td>2 137</td>
<td>776</td>
<td>174</td>
<td>1 615</td>
<td>453</td>
<td>654</td>
<td>4 872</td>
<td>96</td>
</tr>
</tbody>
</table>



-	<a href="http://dx.doi.org/10.1016/j.artint.2012.03.006">MultiCoNER  v2</a> de Fetahu et al. (2023) qui est un jeu de données (pour la partie en français) de 120 682 données d’entraînement et 13 410 de test. Les entités annoncées sont Location (incluant Facility, OtherLOC, HumanSettlement, Station), Creative Work (incluant VisualWork, MusicalWork, WrittenWork, ArtWork, Software), Group (incluant MusicalGRP, PublicCORP, PrivateCORP, AerospaceManufacturer, SportsGRP, CarManufacturer, ORG), Person (incluant Scientist, Artist, Athlete, Politician, Cleric, SportsManager, OtherPER), Product (incluant Clothing, Vehicle, Food, Drink, OtherPROD), Medical (incluant Medication/Vaccine, MedicalProcedure, AnatomicalStructure, Symptom, Disease).  Pour des raisons de pace nous n'affichons pas la répartition des entités (celle-ci est consultable dans la version disponible sur le blog Vaniila).<br>

-	<a href="http://dx.doi.org/10.1016/j.artint.2012.03.006"> Pii-masking-200k </a> de la société <a href="https://ai4privacy.com/">ai4Privacy</a> (2023) qui est un jeu de données (pour la partie en français) de 61 958 données d’entraînement. Les entités annoncées sont Prefix, Firstname, Lastname, Date, Time, Phoneimei, Username, Email, State, Jobarea, Url, City, Currency, Accountname, Creditcardnumber, Creditcardcvv, Phonenumber, Creditcardissuer, Currencysymbol, Amount, Sex, Useragent, Jobtitle, Ipv4, Ipv6, Jobtype, Companyname, Gender, Street, Secondaryaddress, County, Age, Accountnumber, IP, Ethereumaddress, Bitcoinaddress, Middlename, IBAN, Vehiclevrm, Dob, Pin, Password, Currencyname, Litecoinaddress, Currencycode, Buildingnumber, Ordinaldirection, Maskednumber, Zipcode, BIC, Nearbygpscoordinate, MAC, Vehiclevin, Eyecolor, Height et SSN. Pour des raisons de pace nous n'affichons pas la répartition des entités (celle-ci est consultable dans la version disponible sur le blog Vaniila).<br>

<br>


Il s’agit ici des principaux jeux de données « propres », au sens qu’ils sont utilisables facilement car disponibles sur le Hub de Hugging Face. Nous verrons cependant dans la section suivante que la qualité des données de certains jeux de données cités à l’instant est questionnable et a donc nécessité un nettoyage avant de pouvoir les utiliser pour entraîner un modèle. 
<br><br><br>


Il convient de noter qu’il existe d’autres jeux de données de NER en français. Cependant, ceux-ci sont soit de moindre qualité, nécessitent alors un prétraitement très lourd pour être exploitables, soit trop spécialisés. On peut par exemple citer les jeux de données suivants :<br>
-	<a href="https://aclanthology.org/F12-2050/">Annotation référentielle du Corpus Arboré de Paris 7 en entités nommées (Referential named entity annotation of the Paris 7 French TreeBank) [in French]</a> de Sagot et al. (2012) qui est utilisé dans la littérature scientifique comme benchmark du CamemBERT ou du FlauBERT par exemple mais qui n’est pas accessible librement.<br>
-	<a href="http://www.lrec-conf.org/proceedings/lrec2014/workshops/LREC2014Workshop-BioTxtM2014%20Proceedings.pdf#page=33">QUAERO</a> de Névéol et al. (2014) qui est un jeu de données spécialisé dans le domaine médical.<br>
-	<a href="https://arxiv.org/abs/1410.3791">POLYGLOT-NER</a> d’Al-Rfou et al. (2014) est un jeu de données issu de Wikipedia mais présentant d’importants doutes sur la qualité de l’annotation.<br>
-	<a href="https://github.com/EuropeanaNewspapers/ner-corpora"> Europeana Newspapers</a> de Neudecker (2016) qui est un jeu de données obtenu par OCR de vieux journaux de la BnF.<br>
-	<a href="https://github.com/hipe-eval/HIPE-2022-data/blob/main/README.md">HIPE-2022</a> de Faggioli et al. (2022) qui regroupe quatre jeux de données (<a href="https://github.com/hipe-eval/HIPE-2022-data/blob/main/documentation/README-ajmc.md">ajmc</a> de Romanello et al. (2020), <a href="https://dl.acm.org/doi/abs/10.1007/978-3-030-58219-7_21"> hipe2020</a> d’Ehrmann et al. (2020), <a href="https://infoscience.epfl.ch/record/221391">letemps</a> d’Ehrmann et al. (2016), 
<a href="https://dl.acm.org/doi/abs/10.1145/3404835.3463255">newseye</a> d’Hamdi et al. (2021)) obtenus par OCR de vieux journaux (fin XIX - début XXème).<br>
-	<a href="https://arxiv.org/abs/1703.00948.pdf">DAWT</a> de Spasojevic et al. (2017) n’est plus disponible en ligne suite au rachat de l’entreprise ayant créé ce jeu de données.<br><br>


Dans le cadre de nos expérimentations, nous avons décidé de travailler avec deux configurations.<br>
La première consiste à prendre en compte les entités LOC (Localisations), ORG (Organisations) et PER (Personnalités) permettant ainsi de travailler sur la concaténation des jeux MultiCONER, MultiNERD, Pii-masking-200k, Wikiann et WikiNER. C’est-à-dire que dans ce cas-ci, pour les jeux de données gérant d’autres entités que les trois considérées, nous réannotons ces entités supplémentaires à O (Other).<br>
La seconde consiste à prendre en compte les entités LOC (Localisations), ORG (Organisations), PER (Personnalités) et MISC (Divers) permettant ainsi de travailler sur la concaténation des jeux MultiCONER, MultiNERD, Pii-masking-200k et WikiNER. C’est-à-dire que dans ce cas-ci, nous excluons Wikiann qui ne possède pas d’entités MISC et pour les jeux de données possédant des entités autres que LOC, ORG et PER mais pas explicitement MISC, nous réannotons ces entités supplémentaires en MISC.


<br><br> 

# <span style="color: #FF0000"> **Fuites de données et duplication**</span>

En nous intéressant à la qualité des jeux de données listés, nous avons pu constater qu’individuellement ils contenaient des fuites de données entre les échantillons d’entraînement et de test, ainsi que des données dupliquées.<br>


A noter également qu’à l’issue du nettoyage individuel, un nettoyage supplémentaire doit être effectué. En effet, une donnée présente dans l’échantillon d’entraînement d’un jeu de données A et donc non présente dans l’échantillon de test de A, peut être présente dans l’échantillon de test de B, ce qui crée une fuite lors de la création du jeu de données A+B.<br><br>

A titre d’information, les statistiques concernant le nombre de fuites et de duplications pour les cinq jeux de données de NER que nous avons retenus dans le cadre de nos expérimentations sont les suivantes :<br>

-	MultiCONER :<br>
• Fuites entre l'échantillon d'entraînement et l'échantillon de test : 13 lignes soit 0,083 %<br>
• Fuites entre l'échantillon de validation et l'échantillon de test : 0 lignes soit 0 %<br>
• Lignes dupliquées dans l'échantillon d'entraînement : 170 lignes soit 1,081 %<br>
• Lignes dupliquées dans l'échantillon de validation : 1 ligne soit 0,121 %<br>
• Lignes dupliquées dans l'échantillon de test : 2 lignes soit 0,233 %<br>
Ainsi entre les fuites et les duplications, les performances mesurées sur l’échantillon de test sont faussées d’au moins 1,754%.<br>

-	MultiNERD :<br>
• Fuites entre l'échantillon d'entraînement et l'échantillon de test : 69 lignes soit 0,049 %<br>
• Fuites entre l'échantillon de validation et l'échantillon de test : 20 lignes soit 0,114 %<br>
• Lignes dupliquées dans l'échantillon d'entraînement : 2 600 lignes soit 1,846 %<br>
• Lignes dupliquées dans l'échantillon de validation : 201 lignes soit 1,141 %<br>
• Lignes dupliquées dans l'échantillon de test : 58 lignes soit 0,328 %<br>
Ainsi entre les fuites et les duplications, les performances mesurées sur l’échantillon de test sont faussées d’au moins 0,833%.<br>

-	Pii-masking-200k :<br>
	Ce jeu de données ne contient ni fuites ni duplications de données.<br>

-	WikiNER :<br>
• Fuites entre l'échantillon d'entraînement et l'échantillon de test : 22 lignes soit 0,019 %<br>
• Fuites entre l'échantillon de validation et l'échantillon de test : 1 lignes soit 0,017 %<br>
• Lignes dupliquées dans l'échantillon d'entraînement : 562 lignes soit 0,49 %<br>
• Lignes dupliquées dans l'échantillon de validation : 5 lignes soit 0,127 %<br>
• Lignes dupliquées dans l'échantillon de test : 17 lignes soit 0,127 %<br>
Ainsi entre les fuites et les duplications, les performances mesurées sur l’échantillon de test sont faussées d’au moins 0,440%.<br>

-	Wikiann :<br>
• Fuites entre l'échantillon d'entraînement et l'échantillon de test : 742 lignes soit 3,710 %<br>
• Fuites entre l'échantillon de validation et l'échantillon de test : 473 lignes soit 4,730 %<br>
• Lignes dupliquées dans l'échantillon d'entraînement : 1889 lignes soit 9,445 %<br>
• Lignes dupliquées dans l'échantillon de validation : 700 lignes soit 7,000 %<br>
• Lignes dupliquées dans l'échantillon de test : 644 lignes soit 6,440 %<br>
Ainsi entre les fuites et les duplications, les performances mesurées sur l’échantillon de test sont faussées d’au moins 18,590%.<br>

Nous pouvons constater que plus de 80% des jeux de données considérés contenaient des fuites ou des duplications.<br>
<br>

Les statistiques concernant le nombre de fuites et de duplications pour la concaténation des cinq jeux de données de NER que nous avons retenus dans le cadre de nos expérimentations sont les suivantes :<br>

-	Configuration à 3 entités (LOC, ORG et PER) :<br>
• Fuites entre l'échantillon d'entraînement et l'échantillon de test : 1071 lignes soit 0,371 %<br>
• Fuites entre l'échantillon de validation et l'échantillon de test : 613 lignes soit 1,799 %<br>
• Lignes dupliquées dans l'échantillon d'entraînement : 1839 lignes soit 0,638 %<br>
• Lignes dupliquées dans l'échantillon de validation : 8 lignes soit 0,023 %<br>
• Lignes dupliquées dans l'échantillon de test : 8 lignes soit 0,019 %<br>
Ainsi entre les fuites et les duplications, les performances mesurées sur l’échantillon de test sont faussées d’au moins 4,015%.<br><br>

-	Configuration à 4 entités (LOC, ORG, PER et MISC) :<br>
• Fuites entre l'échantillon d'entraînement et l'échantillon de test : 1028 lignes soit 0,384 %<br>
• Fuites entre l'échantillon de validation et l'échantillon de test : 134 lignes soit 0,552 %<br>
• Lignes dupliquées dans l'échantillon d'entraînement : 1779 lignes soit 0,664 %<br>
• Lignes dupliquées dans l'échantillon de validation : 1 lignes soit 0,004 %<br>
• Lignes dupliquées dans l'échantillon de test : 1 lignes soit 0,003 %<br>
Ainsi entre les fuites et les duplications, les performances mesurées sur l’échantillon de test sont faussées d’au moins 3,647%.<br>

<br>

Les jeux de données de NER nettoyés (sans fuites de données ni duplications) sont disponibles sur Hugging Face : <a href="https://hf.co/datasets/CATIE-AQ/frenchNER_3entities"> frenchNER_3entities</a> et <a href="https://hf.co/datasets/CATIE-AQ/frenchNER_4entities"> frenchNER_4entities</a>.


<br><br> 


# <span style="color: #FF0000"> **Quel modèle pour résoudre une tâche de NER ?**</span>


N’importe quel modèle de <i>transformer</i> est capable de résoudre cette tâche, que ce soit un <i>transformer</i> complet (encodeur et décodeur), un <i>transformer</i> décodeur, ou un <i>transformer</i> encodeur. Seule la façon dont sont fournies les données au modèle diffère entre les différentes approches.<br>
En pratique, les modèles de type encodeur sont les plus utilisés. Du fait qu’ils sont les plus adaptés pour résoudre des tâches de classification, et probablement par habitude. En effet, dans le cas du français, les <i>transformers</i> encodeur ont été disponibles avant les <i>transformers</i> décodeur et les <i>transformers</i> complets.<br>

Soulignons également que le modèle CamemBERT de <a href="https://arxiv.org/abs/1911.03894">Martin et al. (2019)</a> semble davantage utilisé que le FlauBERT de <a href="https://arxiv.org/abs/1912.05372">He et al. (2019)</a> pour la tâche de NER, sans qu’il n’y ait d’explications sur la raison. <br>
En novembre 2024, <a href="https://arxiv.org/abs/2411.08868">Antoun et al. (2024)</a> ont introduit le CamemBERT 2.0. Dans ce papier, ils proposent en réalité deux modèles : un CamemBERT2 et un CamemBERTa2. Ces modèles sont entraînés sur plus de données que dans leur première version et ont l'intérêt de pouvoir gérer une séquence de 1024 tokens contre 512 précédemment.<br><br>

Notons aussi qu’en plus du choix du modèle, la tâche de NER peut s’effectuer au niveau du <i>token</i> ou bien au niveau d’un <i>n</i>-gram de <i>tokens</i> consécutifs. Cette étendue de <i>tokens</i> ayant le nom de <i>span</i> dans la littérature.
Une librairie efficace et simple d’utilisation pour effectuer de la NER au niveau d’une <i>span</i> est <a href="https://github.com/tomaarsen/SpanMarkerNER">SpanMarker</a> de Tom Aarsen (2023).<br><br>

Quelques modèles finetunés sur la tâche de NER sont disponibles en open-source. On peut lister : <br>
- Le modèle <a href="https://huggingface.co/flair/ner-french">Ner-french (un modèle Bi-LSTM) finetuné sur WikiNER au niveau du <i>token</i></a> par Flair et plus particulièrement Akbik et al. (2018)<br>
- Le modèle <a href=" https://hf.co/Jean-Baptiste/camembert-ner">Camembert-ner finetuné sur WikiNER au niveau du <i>token</i></a> par Jean-Baptiste Polle<br> 
- Le modèle <a href="https://hf.co/cmarkea/distilcamembert-base-ner">DistillCamemBERT base finetuné sur WikiNER au niveau du <i>token</i></a> par le Crédit Mutuel et plus particulièrement par Delestre et Amar (2022)
<br><br>


La limite de ces modèles est qu’aucun d’entre eux n’utilise la totalité des données disponibles à disposition puisqu’ils sont tous les trois entraînés uniquement sur le jeu de données WikiNER. Cela a pour conséquence (cf. la partie évaluation) de spécialiser les modèles sur des données de type Wikipedia et bride alors leur capacité à généraliser sur de nouvelles données. De plus, comme indiqué précédemment, WikiNER possède des fuites de données et des duplications faussant les performances réelles des modèles.<br>
De plus, aucun modèle de NER en français n’est disponible en taille large.<br><br>


Compte tenu de ces limites, nous avons développé notre propre modèle au CATIE : le <b>NERmembert</b>. Celui-ci utilise l’ensemble des données de qualité à disposition en open-source et a été entraîné en plusieurs configurations. Le tout gratuitement et librement en open-source : <br>
- <a href="https://huggingface.co/CATIE-AQ/NERmembert-base-3entities">https://huggingface.co/CATIE-AQ/NERmembert-base-3entities</a><br>
- <a href="https://huggingface.co/CATIE-AQ/NERmembert-large-3entities">https://huggingface.co/CATIE-AQ/NERmembert-large-3entities</a><br>
- <a href="https://huggingface.co/CATIE-AQ/NERmembert2-3entities">https://huggingface.co/CATIE-AQ/NERmembert2-3entities</a><br>
- <a href="https://huggingface.co/CATIE-AQ/NERmemberta-3entities">https://huggingface.co/CATIE-AQ/NERmemberta-3entities</a><br>
- <a href="https://huggingface.co/CATIE-AQ/NERmembert-base-4entities">https://huggingface.co/CATIE-AQ/NERmembert-base-4entities</a><br>
- <a href="https://huggingface.co/CATIE-AQ/NERmembert-large-4entities">https://huggingface.co/CATIE-AQ/NERmembert-large-4entities</a><br>
- <a href="https://huggingface.co/CATIE-AQ/NERmembert2-4entities">https://huggingface.co/CATIE-AQ/NERmembert2-4entities</a><br>
- <a href="https://huggingface.co/CATIE-AQ/NERmemberta-4entities">https://huggingface.co/CATIE-AQ/NERmemberta-4entities</a><br>


<br><br> 

# <span style="color: #FF0000"> **Métriques et évaluation**</span>

Quelles sont les performances des modèles ? Pour cela décrivons d’abord les métriques sur lesquelles sont évalués les modèles de NER.


## <span style="color: #FFBF00"> **Métriques**</span>


En NER, on donne généralement la précision, le rappel et le score F1 (qui est la moyenne harmonique des deux précédentes métriques) pour chaque entité ainsi qu’au global. L’<i>accuracy</i> peut également être renseignée.


## <span style="color: #FFBF00"> **Évaluation**</span>


D’un point de vue implémentation, pour calculer les métriques énoncées ci-dessus, le mieux est d’utiliser le package Python <a href="https://pypi.org/project/evaluate/">evaluate</a> d’Hugging Face.
<br>


### <span style="color: #51C353"> **Cas à 3 entités**</span>


Ci-dessous, nous listons les tableaux des résultats des performances des différents modèles considérés dans la configuration à trois entités (PER, LOC, ORG) du jeu de données <a href="https://hf.co/datasets/CATIE-AQ/frenchNER_3entities"> frenchNER_3entities</a>.<br>

Pour des raisons de place, nous ne présentons que le F1 des différents modèles. Vous pouvez consulter les résultats complets (i.e. toutes les métriques) dans les cartes de modèles disponibles sur <a href="https://hf.co/collections/CATIE-AQ/french-ner-pack-658aefafe3f7a2dcf0e4dbb4">Hugging Face</a>.<br>


<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>Paramètres</th>
      <th><br>Contexte</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br>110M</td>
        <td><br>512 tokens</td>
        <td><br>0,941</td>
        <td><br>0,883</td>
        <td><br>0,658</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>67,5M</td>
        <td><br>512 tokens</td>
        <td><br>0,942</td>
        <td><br>0,882</td>
        <td><br>0,647</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-4entities">NERmembert-base-4entities</a></td>
        <td><br>110M</td>
        <td><br>512 tokens</td>
        <td><br>0,951</td>
        <td><br>0,894</td>
        <td><br>0,671</td>
    </tr>
        <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-4entities">NERmembert-large-4entities</a></td>
        <td><br>336M</td>
        <td><br>512 tokens</td>
        <td><br>0,958</td>
        <td><br>0,901</td>
        <td><br>0,685</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-3entities">NERmembert-base-3entities</a></td>
        <td><br>110M</td>
        <td><br>512 tokens</td>
        <td><br>0,966</td>
        <td><br>0,940</td>
        <td><br>0,876</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-3entities">NERmembert2-3entities</a> </td>
        <td><br>111M</td>
        <td><br>1024 tokens</td>
        <td><br>0,967</td>
        <td><br>0,942</td>
        <td><br>0,875</td>
    </tr>
        <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-3entities">NERmemberta-3entities</a> </td>
        <td><br>111M</td>
        <td><br>1024 tokens</td>
        <td><br><b>0,970</b></td>
        <td><br>0,943</td>
        <td><br>0,881</td>
      </tr>
      <tr>
      <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-3entities">NERmembert-large-3entities</a></td>
        <td><br>336M</td>
        <td><br>512 tokens</td>
        <td><br>0,969</td>
        <td><br><b>0,947</b></td>
        <td><br><b>0,890</b></td>
    </tr>
</tbody>
</table>
</center>
<br>


On peut observer que les modèles NERmembert (quel que soit le nombre d’entités considérés) performent mieux que les autres modèles. Cela s’explique vraisemblablement par le fait qu’ils aient vu trois fois plus de données lors du finetuning.<br>
De même, on peut voir que les modèles larges ont de meilleurs résultats que les modèles bases.<br>
Notons que la différence de performance est particulièrement marquée entre les NERmembert 3 entités et les modèles non NERmembert avec des écarts de plus de 20 points sur l’entité ORG par exemple.<br><br>
Les modèles NERmembert apparaissent comme plus généralistes comparés aux non NERmembert qui ont été entraînés uniquement sur le jeu de données WikiNER et donc spécialisés sur des données de type Wikipedia. Ils obtiennent d’ailleurs de meilleurs résultats que les NERmembert sur ce jeu de données là.<br>
Nous constatons également ceci : alors que <a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a> annonce les meilleurs résultats sur WikiNER, une fois les fuites et duplications du jeu de données supprimées, c'est en réalité <a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a> qui donne les meilleurs résultats.<br>
Sachant que WikiNER et Wikiann sont tous deux basés sur Wikipédia, nous nous attendions à ce que ces deux modèles obtiennent de bonnes performances sur Wikiann également. A notre surprise, cela ne s'observe pas dans les résultats.<br><br>
Enfin, on peut remarquer un écart entre le modèle NERmembert 3 entités et le modèle NERmembert 4 entités. La différence entre les deux configurations est que les NERmembert 3 entités ont vu un peu plus de données, à savoir le jeu de données Wikiann qui fait environ 25 000 lignes supplémentaires. Dans le détail des résultats par jeu de données disponibles ci-dessous, on peut d’ailleurs voir que le modèle base à 4 entités donne des performances équivalentes ou supérieures au modèle base à 3 entités sur les jeux de données qu’ils ont en commun mais rencontre des difficultés sur Wikiann.<br><br>

Pour plus de détails, vous pouvez étendre l’onglet ci-après afin d’afficher les résultats obtenus pour chacun des jeux de données.<br>


<details>
<summary>Résultats par jeux de données</summary>

<br>

<h4>MultiCoNER</h4> 

<br>

<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br>0,940</td>
        <td><br>0,761</td>
        <td><br>0,723</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>0,921</td>
        <td><br>0,748</td>
        <td><br>0,694</td>
    </tr>
    <tr>
      <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-3entities">NERmembert-base-3entities</a></td>
        <td><br>0,960</td>
        <td><br>0,887</td>
        <td><br>0,876</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-3entities">NERmembert2-3entities</a></td>
        <td><br>0,958</td>
        <td><br>0,876</td>
        <td><br>0,863</td>
    </tr>
        <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-3entities">NERmemberta-3entities</a></td>
        <td><br>0,964</td>
        <td><br>0,865</td>
        <td><br>0,859</td>
      </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-3entities">NERmembert-large-3entities</a></td>
        <td><br><b>0,965</b></td>
        <td><br><b>0,902</b></td>
        <td><br><b>0,896</b></td>
    </tr>
</tbody>
</table>
</center>
<br>

<h4>MultiNERD</h4> 

<br>
<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br>0,962</td>
        <td><br>0,934</td>
        <td><br>0,888</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>0,972</td>
        <td><br>0,938</td>
        <td><br>0,884</td>
    </tr>
    <tr>
      <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-3entities">NERmembert-base-3entities</a></td>
        <td><br>0,985</td>
        <td><br>0,973</td>
        <td><br>0,938</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-3entities">NERmembert2-3entities</a></td>
        <td><br>0,985</td>
        <td><br>0,972</td>
        <td><br>0,933</td>
    </tr>
        <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-3entities">NERmemberta-3entities</a></td>
        <td><br>0,986</td>
        <td><br>0,974</td>
        <td><br>0,945</td>
      </tr>
      <tr>
      <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-3entities">NERmembert-large-3entities</a></td>
        <td><br><b>0,987</b></td>
        <td><br><b>0,979</b></td>
        <td><br><b>0,953</b></td>
    </tr>
</tbody>
</table>
</center>
<br>

<h4>WikiNER</h4>

<br>
<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br><b>0,986</b></td>
        <td><br><b>0,966</b></td>
        <td><br><b>0,938</b></td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>0,983</td>
        <td><br>0,964</td>
        <td><br>0,925</td>
    </tr>
    <tr>
      <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-3entities">NERmembert-base-3entities</a></td>
        <td><br>0,969</td>
        <td><br>0,945</td>
        <td><br>0,878</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-3entities">NERmembert2-3entities</a></td>
        <td><br>0,969</td>
        <td><br>0,946</td>
        <td><br>0,866</td>
    </tr>
        <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-3entities">NERmemberta-3entities</a></td>
        <td><br>0,971</td>
        <td><br>0,948</td>
        <td><br>0,885</td>
      </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-3entities">NERmembert-large-3entities</a></td>
        <td><br>0,972</td>
        <td><br>0,950</td>
        <td><br>0,893</td>
    </tr>
</tbody>
</table>
</center>
<br>

<h4>WikiAnn</h4>

<br>
<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br>0,867</td>
        <td><br>0,722</td>
        <td><br>0,451</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>0,862</td>
        <td><br>0,722</td>
        <td><br>0,451</td>
    </tr>
    <tr>
      <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-3entities">NERmembert-base-3entities</a></td>
        <td><br>0,947</td>
        <td><br>0,906</td>
        <td><br>0,886</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-3entities">NERmembert2-3entities</a></td>
        <td><br>0,950</td>
        <td><br>0,911</td>
        <td><br><b>0,910</b></td>
    </tr>
        <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-3entities">NERmemberta-3entities</a></td>
        <td><br><b>0,953</b></td>
        <td><br>0,902</td>
        <td><br>0,890</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-3entities">NERmembert-large-3entities</a></td>
        <td><br>0.949</td>
        <td><br><b>0.912</b></td>
        <td><br>0.899</td>
    </tr>
</tbody>
</table>
</center>
</details>

<br><br>

### <span style="color: #51C353"> **Cas à 4 entités**</span>


Ci-dessous, nous listons les tableaux des résultats des performances des différents modèles considérés dans la configuration à quatre entités (PER, LOC, ORG, MISC) du jeu de données <a href="https://hf.co/datasets/CATIE-AQ/frenchNER_4entities"> frenchNER_4entities</a>.
<br>

<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>Paramètres</th>
      <th><br>Contexte</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
      <th><br>MISC</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br>110M</td>
        <td><br>512 tokens</td>
        <td><br>0,971</td>
        <td><br>0,947</td>
        <td><br>0,902</td>
        <td><br>0,663</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>67,5M</td>
        <td><br>512 tokens</td>
        <td><br>0,974</td>
        <td><br>0,948</td>
        <td><br>0,892</td>
        <td><br>0,658</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-4entities">NERmembert-base-4entities</a></td>
        <td><br>110M</td>
        <td><br>512 tokens</td>
        <td><br>0,978</td>
        <td><br>0,958</td>
        <td><br>0,903</td>
        <td><br>0,814</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-4entities">NERmembert2-4entities</a></td>
        <td><br>111M</td>
        <td><br>1024 tokens</td>
        <td><br>0,978</td>
        <td><br>0,958</td>
        <td><br>0,901</td>
        <td><br>0,806</td>
    </tr>
    <tr>
        <td rowspan="1"><a href="https://hf.co/CATIE-AQ/NERmemberta-4entities">NERmemberta-4entities</a></td>
        <td><br>111M</td>
        <td><br>1024 tokens</td>
        <td><br>0,979</td>
        <td><br>0,961</td>
        <td><br>0,915</td>
        <td><br>0,812</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-4entities">NERmembert-large-4entities</a></td>
        <td><br>336M</td>
        <td><br>512 tokens</td>
        <td><br><b>0,982</b></td>
        <td><br><b>0,964</b></td>
        <td><br><b>0,919</b></td>
        <td><br><b>0,834</b></td>
    </tr>
</tbody>
</table>
</center>
<br>


Encore une fois, pour des raisons de place, nous ne présentons que le F1 des différents modèles. Vous pouvez consulter les résultats complets (i.e. toutes les métriques) dans les cartes de modèles disponibles sur <a href="https://hf.co/collections/CATIE-AQ/french-ner-pack-658aefafe3f7a2dcf0e4dbb4">Hugging Face</a>.<br><br>

Les résultats sont dans le même sillon que ce qu’on peut observer pour la configuration à 3 entités.
A savoir que les modèles NERmembert (quel que soit le nombre d’entités considérés) performent mieux que les autres modèles et que les modèles larges ont de meilleurs résultats que les modèles bases.<br>
Sur les entités PER, LOC et ORG, les NERmembert 3 entités ont des résultats semblables aux NERmembert 4 entités. L’intérêt des NERmembert 4 entités est qu’ils gèrent l’entité supplémentaire MISC.<br>
A nouveau, les NERmembert apparaissent comme plus généralistes en comparaison aux non NERmembert. Comme pour la configuration à trois entités, ces modèles obtiennent de meilleurs résultats sur WikiNER mais ont des difficultés sur les autres jeux de données.<br>
Il y a un écart important sur la catégorie MISC. Une explication pourrait être la nature de la définition de cette entité. En effet, pour WikiNER, il s’agit principalement de noms d’œuvres (livres ou films par exemple), là où MultiNERD et MultiCoNER gèrent en plus des noms médicaux (maladies/symptômes) et des produits (marques de véhicule/nourriture/vêtements).<br><br>


Pour plus de détails, vous pouvez étendre l’onglet ci-après afin d’afficher les résultats obtenus pour chacun des jeux de données.<br>


<details>
<summary>Résultats par jeux de données</summary>

<br>

<h4>MultiCoNER</h4>

<br>
<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
      <th><br>MISC</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br>0,940</td>
        <td><br>0,761</td>
        <td><br>0,723</td>
        <td><br>0,560</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>0,921</td>
        <td><br>0,748</td>
        <td><br>0,694</td>
        <td><br>0,530</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-4entities">NERmembert-base-4entities</a></td>
        <td><br>0,960</td>
        <td><br>0,890</td>
        <td><br>0,867</td>
        <td><br>0,852</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-4entities">NERmembert2-4entities</a></td>
        <td><br>0,964</td>
        <td><br>0,888</td>
        <td><br>0,864</td>
        <td><br>0,850</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-4entities">NERmemberta-4entities</a></td>
        <td><br>0,966</td>
        <td><br>0,891</td>
        <td><br>0,867</td>
        <td><br>0,862</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-4entities">NERmembert-large-4entities</a></td>
        <td><br><b>0,969</b></td>
        <td><br><b>0,919</b></td>
        <td><br><b>0,904</b></td>
        <td><br><b>0,864</b></td>
    </tr>
</tbody>
</table>
</center>
<br>

<h4>MultiNERD</h4>

<br>
<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
      <th><br>MISC</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br>0,962</td>
        <td><br>0,934</td>
        <td><br>0,888</td>
        <td><br>0,419</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>0,972</td>
        <td><br>0,938</td>
        <td><br>0,884</td>
        <td><br>0,430</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-4entities">NERmembert-base-4entities</a></td>
        <td><br>0,985</td>
        <td><br>0,973</td>
        <td><br>0,938</td>
        <td><br>0,770</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-4entities">NERmembert2-4entities</a></td>
        <td><br>0,986</td>
        <td><br>0,974</td>
        <td><br>0,937</td>
        <td><br>0,761</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-4entities">NERmemberta-4entities</a></td>
        <td><br><b>0,987</b></td>
        <td><br><b>0,976</b></td>
        <td><br>0,942</td>
        <td><br>0,770</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-4entities">NERmembert-large-4entities</a></td>
        <td><br><b>0,987</b></td>
        <td><br>0,976</td>
        <td><br>0,948</td>
        <td><br><b>0,790</b></td>
    </tr>
</tbody>
</table>
</center>
<br>

<h4>WikiNER</h4>

<br>
<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
      <th><br>MISC</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/Jean-Baptiste/camembert-ner">Jean-Baptiste/camembert-ner</a></td>
        <td><br><b>0,986</b></td>
        <td><br><b>0,966</b></td>
        <td><br><b>0,938</b></td>
        <td><br><b>0,938</b></td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/cmarkea/distilcamembert-base-ner">cmarkea/distilcamembert-base-ner</a></td>
        <td><br>0,983</td>
        <td><br>0,964</td>
        <td><br>0,925</td>
        <td><br>0,926</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-4entities">NERmembert-base-4entities</a></td>
        <td><br>0,970</td>
        <td><br>0,945</td>
        <td><br>0,876</td>
        <td><br>0,872</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert2-4entities">NERmembert2-4entities</a></td>
        <td><br>0,968</td>
        <td><br>0,945</td>
        <td><br>0,874</td>
        <td><br>0,871</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmemberta-4entities">NERmemberta-4entities</a></td>
        <td><br>0,969</td>
        <td><br>0,950</td>
        <td><br>0,897</td>
        <td><br>0,871</td>
    </tr>
      <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-large-4entities">NERmembert-large-4entities</a></td>
        <td><br>0,975</td>
        <td><br>0,953</td>
        <td><br>0,896</td>
        <td><br>0,893</td>
    </tr>
</tbody>
</table>
</center>
</details>

<br><br>

### <span style="color: #51C353"> **Modèles de span**</span>


Nous avons listé ci-dessus des modèles entraînés au niveau du <i>token</i>. 
Nous avons également entraîné des modèles au niveau de <i>n</i>-gram de <i>tokens</i> consécutifs avec la librairie SpanMarker. 
La littérature sur le sujet (le <a href="https://raw.githubusercontent.com/tomaarsen/SpanMarkerNER/main/thesis.pdf">mémoire de Tom Aarsen</a> auteur de SpanMarker en fait une bonne synthèse) tend à indiquer que les modèles entraînés au niveau de <i>span</i> donnent de meilleures performances que les modèles entraînés au niveau du <i>token</i>.<br>

Nous obtenons des résultats inverses dans nos expériences :


<h4>Cas à 3 entités</h4>

<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br>Span Marker (frenchNER_3entities)</td>
        <td><br>0,959</td>
        <td><br>0,924</td>
        <td><br>0,850</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-3entities">NERmembert-base-3entities</a></td>
        <td><br>0,966</td>
        <td><br>0,940</td>
        <td><br>0,876</td>
    </tr>
</tbody>
</table>
</center>

<h4>Cas à 4 entités</h4>

<center>
<table>
<thead>
    <tr>
      <th><br>Modèle</th>
      <th><br>PER</th>
      <th><br>LOC</th>
      <th><br>ORG</th>
      <th><br>MISC</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td rowspan="1"><br>Span Marker (frenchNER_4entities)</td>
        <td><br>0,966</td>
        <td><br>0,939</td>
        <td><br>0,892</td>
        <td><br>0,760</td>
    </tr>
    <tr>
        <td rowspan="1"><br><a href="https://hf.co/CATIE-AQ/NERmembert-base-4entities">NERmembert-base-4entities</a></td>
        <td><br>0,978</td>
        <td><br>0,958</td>
        <td><br>0,903</td>
        <td><br>0,814</td>
    </tr>
</tbody>
</table>
</center>
<br>


Nous avançons deux possibilités à ces résultats. La première est que les performances peuvent varier en fonction des langues (Tom Aarsen nous ayant indiqué que des observations similaires ont été observées en espagnol).
La seconde est que les résultats obtenus en anglais sont biaisés et donc en réalité non fiables. En effet, le jeu de données CoNLL2003 qui est massivement utilisé en anglais contient lui aussi des fuites de données et duplications :<br>
• Fuites entre l'échantillon d'entraînement et l'échantillon de test 78 lignes soit 0.556%.<br>
• Fuites entre l'échantillon de validation et l'échantillon de test : 25 lignes soit 0.769%.<br>
• Lignes dupliquées dans l'échantillon d'entraînement : 1 350 lignes soit 9.615%.<br>
• Lignes dupliquées dans l'échantillon de validation : 269 lignes soit 8.277%.<br>
• Lignes dupliquées dans l'échantillon de test : 269 lignes soit 7.79 %.<br>

Ainsi entre les fuites et les duplications, les performances mesurées sur l’échantillon de test sont faussées d’au moins 10,77%.  

Notons qu'un modèle SpanMarker prend trois fois plus de temps qu’un NERmembert.  

Enfin, terminons cette section en soulignant que depuis la premire version de cet article de blog, la librairie <a href="https://github.com/urchade/GLiNER">GLiNER</a> de Zaratiana et al. (2023) permet également d'entraîner des modèles à span. Il nous faudrait réaliser la même expérience avec cette librairie.

<br><br> 

# <span style="color: #FF0000"> **Exemple d’utilisations**</span>

```python
from transformers import pipeline

ner = pipeline('token-classification', model='CATIE-AQ/NERmembert-base-4entities', tokenizer='CATIE-AQ/NERmembert-base-4entities', aggregation_strategy="simple")

results = ner(
"Le dévoilement du logo officiel des JO s'est déroulé le 21 octobre 2019 au Grand Rex. Ce nouvel emblème et cette nouvelle typographie ont été conçus par le designer Sylvain Boyer avec les agences Royalties & Ecobranding. Rond, il rassemble trois symboles : une médaille d'or, la flamme olympique et Marianne, symbolisée par un visage de femme mais privée de son bonnet phrygien caractéristique. La typographie dessinée fait référence à l'Art déco, mouvement artistique des années 1920, décennie pendant laquelle ont eu lieu pour la dernière fois les Jeux olympiques à Paris en 1924. Pour la première fois, ce logo sera unique pour les Jeux olympiques et les Jeux paralympiques."
)

print(results)
```
```python
[{'entity_group': 'MISC', 'score': 0.9456432, 'word': 'JO', 'start': 36, 'end': 38},
{'entity_group': 'LOC', 'score': 0.9990527, 'word': 'Grand Rex', 'start': 75, 'end': 84},
{'entity_group': 'PER', 'score': 0.99884754, 'word': 'Sylvain Boyer', 'start': 165, 'end': 178},
{'entity_group': 'ORG', 'score': 0.99118334, 'word': 'Royalties & Ecobranding', 'start': 196, 'end': 219},
{'entity_group': 'PER', 'score': 0.9446552, 'word': 'Marianne', 'start': 299, 'end': 307},
{'entity_group': 'MISC', 'score': 0.97599506, 'word': 'Art déco', 'start': 438, 'end': 446},
{'entity_group': 'MISC', 'score': 0.99798834, 'word': 'Jeux olympiques', 'start': 550, 'end': 565},
{'entity_group': 'LOC', 'score': 0.7205312, 'word': 'Paris', 'start': 568, 'end': 573},
{'entity_group': 'MISC', 'score': 0.996698, 'word': 'Jeux olympiques', 'start': 635, 'end': 650},
{'entity_group': 'MISC', 'score': 0.9955608, 'word': 'Jeux paralympiques', 'start': 658, 'end': 676}]
```

<br>

Si vous souhaitez tester le modèle de manière plus directe, un démonstrateur a été créé et est hébergé sous la forme d’un <i>Space</i> sur Hugging Face disponible <a href="https://huggingface.co/spaces/CATIE-AQ/NERmembert">ici</a> (démo en plein écran) ou bien ci-dessous :


<iframe
	src="https://catie-aq-nermembert.hf.space"
	frameborder="0"
	width="950"
	height="600"
></iframe>
<br><br> 


#  <span style="color: #FF0000"> **Améliorations possibles**</span>

Terminons en listant des améliorations possibles à ce travail. <br>

Dans la section sur la description des données, nous avons listé les effectifs disponibles par type d’entités. Il est possible de relever un déséquilibre se ressentant par la suite sur les résultats (pour les entités ORG et MISC notamment). Un travail important consisterait ainsi à équilibrer les entités à notre disposition en effectuant par exemple de l’augmentation de données par simple substitution d’une valeur d’une entité par un autre du même type. Cela peut se faire en utilisant des entités déjà présentes dans notre jeu de données (ce qui pourrait permettre de rendre la valeur d’une entité plus robuste au contexte l’entourant) ou bien issues de sources externes (pour les ORG on peut penser à des données issues des chambres de commerce ou de l’INSEE par exemple).<br> 

Un autre travail consisterait à ajouter d’autres entités mais nécessiterait un effort conséquent d’annotation.

<br><br> 

# <span style="color: #FF0000"> **Conclusion**</span>

Nous introduisons le modèle NERmembert en huit versions différentes. L'ensemble des modèles entraînés sont accompagnés des jeux de données que nous avons utilisés qui sont sans fuites de données ou duplications. Le tout est librement accessible gratuitement sur <a href="https://huggingface.co/collections/CATIE-AQ/french-ner-pack-658aefafe3f7a2dcf0e4dbb4">Hugging Face</a>. 

<br><br> 

# <span style="color: #FF0000"> **Références**</span>

- <a href="https://aclanthology.org/W03-0419/">Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition</a> de Erik F. Tjong Kim Sang et Fien De Meulder (2003)<br>
- <a href="">http://dx.doi.org/10.1016/j.artint.2012.03.006">Learning multilingual named entity recognition from Wikipedia</a> de Nothman et al. (2013)<br>
- <a href="https://arxiv.org/abs/1902.00193">Massively Multilingual Transfer for NER</a> de Rahimi et al. (2019)<br>
- <a href="https://www.aclweb.org/anthology/P19-1015/">Massively Multilingual Transfer for NER</a> de Pan, Xiaoman, et al. (2019)<br>
- <a href="https://aclanthology.org/2022.findings-naacl.60">MultiNERD: A Multilingual, Multi-Genre and Fine-Grained Dataset for Named Entity Recognition (and Disambiguation)</a> de Tedeschi et Navigli (2022)<br>
- <a href="https://arxiv.org/abs/2305.06586">SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2)</a> de Fetahu et al. (2023)<br>
- <a href="https://huggingface.co/datasets/ai4privacy/pii-masking-200k">Pii-masking-200k</a> d’ai4Privacy (2023)<br>
- <a href="https://aclanthology.org/F12-2050/">Annotation référentielle du Corpus Arboré de Paris 7 en entités nommées (Referential named entity annotation of the Paris 7 French TreeBank) [in French]</a> de Sagot et al. (2012)<br>
- <a href="http://www.lrec-conf.org/proceedings/lrec2014/workshops/LREC2014Workshop-BioTxtM2014%20Proceedings.pdf#page=33">The Quaero French Medical Corpus: A Ressource for Medical Entity Recognition and Normalization</a> de Névéol et al. (2014)<br>
- <a href="https://arxiv.org/abs/1410.3791">POLYGLOT-NER: Massive Multilingual Named Entity Recognition</a> d’Al-Rfou et al. (2014)<br>
- <a href="https://github.com/EuropeanaNewspapers/ner-corpora"> Europeana Newspapers</a> de Neudecker (2016)<br>
- <a href="https://github.com/hipe-eval/HIPE-2022-data/blob/main/README.md">HIPE-2022</a> de Faggioli et al. (2022)<br>
- <a href="https://github.com/hipe-eval/HIPE-2022-data/blob/main/documentation/README-ajmc.md">ajmc</a> de Romanello et al. (2020)<br>
- <a href="https://dl.acm.org/doi/abs/10.1007/978-3-030-58219-7_21">Overview of CLEF HIPE 2020: Named Entity Recognition and Linking on Historical Newspapers</a> d’Ehrmann et al. (2020)<br>
- <a href="https://infoscience.epfl.ch/record/221391">Diachronic Evaluation of NER Systems on Old Newspapers</a> d’Ehrmann et al. (2016)<br>
- <a href="https://dl.acm.org/doi/abs/10.1145/3404835.3463255">A Multilingual Dataset for Named Entity Recognition, Entity Linking and Stance Detection in Historical Newspapers</a> d’Hamdi et al. (2021)<br>
- <a href="https://arxiv.org/abs/1703.00948.pdf">DAWT: Densely Annotated Wikipedia Texts across multiple languages</a> de Spasojevic et al. (2017) <br>
- <a href="https://arxiv.org/abs/1911.03894">CamemBERT: a Tasty French Language Model</a> de Martin et al. (2019)<br>
- <a href="https://arxiv.org/abs/1912.05372">FlauBERT: Unsupervised Language Model Pre-training for French</a> de He et al. (2019<br>
- <a href="https://arxiv.org/abs/2411.08868">CamemBERT 2.0: A Smarter French Language Model Aged to Perfection</a> de Antoun et al. (2024)<br>
- <a href="https://github.com/tomaarsen/SpanMarkerNER">SpanMarker</a> d’Aarsen (2023)<br>
- <a href="https://arxiv.org/abs/2311.08526">GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer</a> de Zaratiana et al. (2023)<br>
- <a href="https://huggingface.co/flair/ner-french">ner-french</a> d’Akbik et al. (2018)<br>
- <a href="https://huggingface.co/Jean-Baptiste/camembert-ner">camembert-ner</a> de Polle (2021)<br>
- <a href="https://huggingface.co/cmarkea/distilcamembert-base-ner"> distilcamembert</a> de Delestre et Amar (2022)

<br><br> 


# <span style="color: #FF0000"> **Citations**</span>
### Modèles
```
@misc {NERmemberta2024,
    author       = { {BOURDOIS, Loïck} },  
    organization = { {Centre Aquitain des Technologies de l'Information et Electroniques} },  
    title        = { NERmemberta-3entities (Revision 989f2ee) },
    year         = 2024,
    url          = { https://huggingface.co/CATIE-AQ/NERmemberta-3entities },
    doi          = { 10.57967/hf/3640 },
    publisher    = { Hugging Face }
}
```
```
@misc {NERmembert2024,
    author       = { {BOURDOIS, Loïck} },  
    organization = { {Centre Aquitain des Technologies de l'Information et Electroniques} },  
    title        = { NERmembert-large-4entities (Revision 1cd8be5) },
    year         = 2024,
    url          = { https://huggingface.co/CATIE-AQ/NERmembert-large-4entities },
    doi          = { 10.57967/hf/1752 },
    publisher    = { Hugging Face }
}
```

### Jeux de données
```
@misc {frenchNER2024,
    author       = { {BOURDOIS, Loïck} },  
    organization = { {Centre Aquitain des Technologies de l'Information et Electroniques} },  
    title        = { frenchNER_4entities (Revision f1e8fef) },
    year         = 2024,
    url          = { https://huggingface.co/datasets/CATIE-AQ/frenchNER_4entities },
    doi          = { 10.57967/hf/1751 },
    publisher    = { Hugging Face }
}
```
